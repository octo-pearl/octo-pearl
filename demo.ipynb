{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of OCTO+ and other object placement methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/octo-pearl/octo-pearl.git\n",
    "%cd octo-pearl\n",
    "%pip install -qe ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p weights\n",
    "!wget -q -O weights/sam_vit_h_4b8939.pth https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
    "!wget -q -O weights/ram_plus_swin_large_14m.pth https://huggingface.co/xinyu1205/recognize-anything-plus-model/resolve/main/ram_plus_swin_large_14m.pth\n",
    "!wget -q -O weights/groundingdino_swint_ogc.pth https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "OBJECT_TO_PLACE = \"cupcake\"\n",
    "IMAGE_PATH = \"assets/test_img.jpg\"\n",
    "\n",
    "image = Image.open(IMAGE_PATH)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: Image Understanding\n",
    "Generate and filter a list of \"tags\", or objects, in the image\n",
    "\n",
    "Note: These functions may take a while to run the first time they are called, as they have to load the models from the disk into the CPU/GPU. Subsequent calls should be much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octo_pearl.placement.tagging import get_tags_scp, get_tags_gpt4v, get_tags_ram\n",
    "# tags = get_tags_scp(image)\n",
    "# tags = get_tags_gpt4v(image)\n",
    "tags = get_tags_ram(image, threshold_multiplier=0.8)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octo_pearl.placement.filtering import filter_tags_clipseg, filter_tags_vilt, filter_tags_gdino\n",
    "# filtered_tags = filter_tags_clipseg(image, tags)\n",
    "# filtered_tags = filter_tags_vilt(image, tags)\n",
    "filtered_tags = filter_tags_gdino(image, tags)\n",
    "filtered_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: Reasoning\n",
    "Select which tag the chosen object should be placed on\n",
    "\n",
    "Note: You can directly pass in your `OPENAI_API_KEY` as a parameter to the `select_best_tag` function. You can also add your `OPENAI_API_KEY` to the environment variable (.env) file in `octo-pearl/placement/.env` path. The .env file should contain the following:\n",
    "```\n",
    "OPENAI_API_KEY=<your_api_key>\n",
    "```\n",
    "\n",
    "For `select_best_tag` the function signature is:\n",
    "```\n",
    "select_best_tag(filtered_tags: List[str], object_to_place: str, api_key: str = \"\") -> str\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octo_pearl.placement.selecting import select_best_tag\n",
    "selected_object = select_best_tag(filtered_tags, OBJECT_TO_PLACE, api_key=\"<your_api_key>\")\n",
    "selected_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3: Locating\n",
    "Select a 2D location corresponding to the selected tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octo_pearl.placement.locating import get_location_clipseg, get_location_gsam\n",
    "# x, y = get_location_clipseg(image, selected_object)\n",
    "x, y = get_location_gsam(image, selected_object)\n",
    "plt.imshow(image)\n",
    "plt.scatter(x, y, c=\"red\", s=50)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating\n",
    "For the evaluation, we will use an image from NYU Depth Dataset V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octo_pearl.eval.pearl import placement_score\n",
    "IMAGE_NAME = \"000749.png\"\n",
    "image = Image.open(f\"octo_pearl/eval/data/images/{IMAGE_NAME}\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the object \"computer\", since it is included in PEARL for this image. This is the PEARL segmentation mask of valid locations for a computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octo_pearl.eval.pearl import create_mask\n",
    "OBJECT_TO_PLACE = \"computer\"\n",
    "mask = create_mask(IMAGE_NAME, OBJECT_TO_PLACE)\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A computer would appear natural if it were centered on the table, at around (100, 325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 100\n",
    "y = 325\n",
    "plt.imshow(image)\n",
    "plt.scatter(x, y, c=\"red\", s=50)\n",
    "in_mask, pearl_score = placement_score(IMAGE_NAME, OBJECT_TO_PLACE, x, y)\n",
    "print(f\"In mask: {in_mask}\")\n",
    "print(f\"PEARL score: {pearl_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computer would look less natural if it were at the edge of the table, at around (200, 325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 200\n",
    "y = 325\n",
    "plt.imshow(image)\n",
    "plt.scatter(x, y, c=\"red\", s=50)\n",
    "in_mask, pearl_score = placement_score(IMAGE_NAME, OBJECT_TO_PLACE, x, y)\n",
    "print(f\"In mask: {in_mask}\")\n",
    "print(f\"PEARL score: {pearl_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computer would look very unnatural if it were on a cabinet, at around (200, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 200\n",
    "y = 50\n",
    "plt.imshow(image)\n",
    "plt.scatter(x, y, c=\"red\", s=50)\n",
    "in_mask, pearl_score = placement_score(IMAGE_NAME, OBJECT_TO_PLACE, x, y)\n",
    "print(f\"In mask: {in_mask}\")\n",
    "print(f\"PEARL score: {pearl_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
